const axios = require('axios');

/**
 * LLMæœåŠ¡ - åŸºäºLM Studioçš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
 */
class LLMService {
  constructor() {
    this.baseURL = 'http://localhost:1234/v1'; // LM Studioé»˜è®¤åœ°å€
    this.model = 'local-model'; // å°†è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ¨¡å‹
    this.maxTokens = 2048;
    this.temperature = 0.7;
    this.isInitialized = false;
    this.client = null;
  }

  /**
   * åˆå§‹åŒ–LLMæœåŠ¡
   */
  async initialize() {
    if (this.isInitialized) {
      return;
    }

    try {
      console.log('æ­£åœ¨åˆå§‹åŒ–LM StudioæœåŠ¡...');
      console.log(`è¿æ¥åœ°å€: ${this.baseURL}`);

      // åˆ›å»ºHTTPå®¢æˆ·ç«¯
      this.client = axios.create({
        baseURL: this.baseURL,
        timeout: 60000,
        headers: {
          'Content-Type': 'application/json'
        }
      });

      // æµ‹è¯•è¿æ¥å¹¶è·å–æ¨¡å‹
      await this.detectModel();

      this.isInitialized = true;
      console.log('âœ… LM StudioæœåŠ¡åˆå§‹åŒ–å®Œæˆ');
    } catch (error) {
      console.error('âŒ LM StudioæœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error.message);
      throw new Error(`LM StudioæœåŠ¡åˆå§‹åŒ–å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æ£€æµ‹å¯ç”¨æ¨¡å‹
   */
  async detectModel() {
    try {
      console.log('ğŸ” æ£€æµ‹LM Studioä¸­çš„æ¨¡å‹...');

      const response = await this.client.get('/models');
      const models = response.data.data || [];

      if (models.length === 0) {
        throw new Error('LM Studioä¸­æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œè¯·å…ˆåœ¨LM Studioä¸­åŠ è½½ä¸€ä¸ªæ¨¡å‹');
      }

      // ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
      this.model = models[0].id;

      console.log(`âœ… å‘ç° ${models.length} ä¸ªå¯ç”¨æ¨¡å‹:`);
      models.forEach((model, index) => {
        const marker = index === 0 ? 'ğŸ‘‰' : '  ';
        console.log(`${marker} ${model.id}`);
      });
      console.log(`ğŸ“ ä½¿ç”¨æ¨¡å‹: ${this.model}`);

    } catch (error) {
      if (error.code === 'ECONNREFUSED') {
        throw new Error('æ— æ³•è¿æ¥åˆ°LM Studioï¼Œè¯·ç¡®ä¿ï¼š\n1. LM Studioå·²å¯åŠ¨\n2. å·²åŠ è½½ä¸€ä¸ªæ¨¡å‹\n3. æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ (é»˜è®¤ç«¯å£1234)');
      }
      throw error;
    }
  }

  /**
   * ç”Ÿæˆå›ç­”
   * @param {string} prompt - æç¤ºè¯
   * @param {Object} options - ç”Ÿæˆé€‰é¡¹
   * @returns {Promise<Object>} ç”Ÿæˆç»“æœ
   */
  async generateAnswer(prompt, options = {}) {
    await this.initialize();

    try {
      const requestData = {
        model: this.model,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: options.maxTokens || this.maxTokens,
        temperature: options.temperature || this.temperature,
        stream: false
      };

      console.log(`ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”... (æ¨¡å‹: ${this.model})`);
      const startTime = Date.now();

      const response = await this.client.post('/chat/completions', requestData);

      const endTime = Date.now();
      const responseTime = endTime - startTime;

      if (!response.data?.choices?.[0]?.message?.content) {
        throw new Error('LM Studioè¿”å›äº†ç©ºå“åº”');
      }

      const answer = response.data.choices[0].message.content;
      const usage = response.data.usage || {};

      console.log(`âœ… å›ç­”ç”Ÿæˆå®Œæˆ (${responseTime}ms)`);
      console.log(`ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥${usage.prompt_tokens || 0}, è¾“å‡º${usage.completion_tokens || 0}`);

      return {
        answer: answer.trim(),
        usage,
        responseTime,
        model: this.model
      };

    } catch (error) {
      console.error('âŒ å›ç­”ç”Ÿæˆå¤±è´¥:', error.message);

      if (error.response?.data) {
        console.error('APIé”™è¯¯è¯¦æƒ…:', error.response.data);
      }

      throw new Error(`å›ç­”ç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æµå¼ç”Ÿæˆå›ç­”
   * @param {string} prompt - æç¤ºè¯
   * @param {Function} onChunk - æ¥æ”¶æ•°æ®å—çš„å›è°ƒå‡½æ•°
   * @param {Object} options - ç”Ÿæˆé€‰é¡¹
   */
  async generateAnswerStream(prompt, onChunk, options = {}) {
    await this.initialize();

    try {
      const requestData = {
        model: options.model || this.model,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: options.maxTokens || this.maxTokens,
        temperature: options.temperature || this.temperature,
        stream: true
      };

      console.log(`ğŸŒŠ å¼€å§‹æµå¼ç”Ÿæˆå›ç­”... (æ¨¡å‹: ${requestData.model})`);

      const response = await this.client.post('/chat/completions', requestData, {
        responseType: 'stream'
      });

      let fullAnswer = '';
      
      response.data.on('data', (chunk) => {
        const lines = chunk.toString().split('\n');
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            
            if (data === '[DONE]') {
              console.log('âœ… æµå¼ç”Ÿæˆå®Œæˆ');
              return;
            }

            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              
              if (content) {
                fullAnswer += content;
                onChunk(content, fullAnswer);
              }
            } catch (parseError) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      });

      return new Promise((resolve, reject) => {
        response.data.on('end', () => {
          resolve({
            answer: fullAnswer,
            model: requestData.model
          });
        });

        response.data.on('error', (error) => {
          reject(new Error(`æµå¼ç”Ÿæˆå¤±è´¥: ${error.message}`));
        });
      });

    } catch (error) {
      console.error('âŒ æµå¼ç”Ÿæˆå¤±è´¥:', error.message);
      throw new Error(`æµå¼ç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æ„å»ºRAGæç¤ºè¯
   * @param {string} question - ç”¨æˆ·é—®é¢˜
   * @param {Array} contexts - æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
   * @param {Object} options - é€‰é¡¹
   * @returns {string} æ„å»ºçš„æç¤ºè¯
   */
  buildRAGPrompt(question, contexts, options = {}) {
    const systemPrompt = options.systemPrompt || `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”åŸºäºæä¾›æ–‡æ¡£çš„é—®é¢˜ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å›ç­”è¦æ±‚ï¼š
1. åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹è¿›è¡Œå›ç­”
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†
4. å¯ä»¥é€‚å½“å¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“å†…å®¹`;

    let contextText = '';
    if (contexts && contexts.length > 0) {
      contextText = 'å‚è€ƒæ–‡æ¡£ï¼š\n\n';
      contexts.forEach((context, index) => {
        contextText += `æ–‡æ¡£${index + 1}ï¼š\n${context.content}\n\n`;
      });
    }

    const prompt = `${systemPrompt}

${contextText}

ç”¨æˆ·é—®é¢˜ï¼š${question}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š`;

    return prompt;
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€
   */
  async getStatus() {
    try {
      if (!this.isInitialized) {
        return {
          status: 'not_initialized',
          isInitialized: false,
          baseURL: this.baseURL,
          model: this.model
        };
      }

      const response = await this.client.get('/models');
      const models = response.data.data || [];

      return {
        status: 'running',
        isInitialized: true,
        baseURL: this.baseURL,
        model: this.model,
        availableModels: models.map(m => m.id),
        config: {
          maxTokens: this.maxTokens,
          temperature: this.temperature
        }
      };
    } catch (error) {
      return {
        status: 'error',
        isInitialized: this.isInitialized,
        error: error.message,
        baseURL: this.baseURL
      };
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup() {
    this.client = null;
    this.isInitialized = false;
    console.log('LLMæœåŠ¡èµ„æºå·²æ¸…ç†');
  }
}

module.exports = new LLMService();
